{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0614 00:57:35.926011  1796 file_utils.py:39] PyTorch version 1.2.0+cu92 available.\n",
      "C:\\Users\\danil\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import math\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from make_fn_data import load_fn_data\n",
    "from neural_net import Model, NpClassDataset\n",
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics\n",
      "# data points:  200751\n",
      "# lex units without data:  3271\n"
     ]
    }
   ],
   "source": [
    "# Load and prepare data\n",
    "data = load_fn_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 01:01:55.699022  1796 tokenization_utils.py:1075] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\\Users\\danil/.cache\\torch\\transformers\\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "I0615 01:01:55.942373  1796 configuration_utils.py:265] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at C:\\Users\\danil/.cache\\torch\\transformers\\4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "I0615 01:01:55.943370  1796 configuration_utils.py:301] Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I0615 01:01:56.169764  1796 modeling_utils.py:650] loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at C:\\Users\\danil/.cache\\torch\\transformers\\f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "bert_model.eval()\n",
    "bert_model.to('cuda')\n",
    "print(bert_model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# datapoints =  62445\n",
      "max labels =  828\n",
      "829\n"
     ]
    }
   ],
   "source": [
    "# create datapoints from data\n",
    "\n",
    "frame_dict = {}\n",
    "frame_dict_rev = {}\n",
    "\n",
    "inputs = []\n",
    "labels = []\n",
    "\n",
    "for lu in data[:5000]:\n",
    "    frame =  lu[\"frame\"]\n",
    "    if not frame in frame_dict.keys():\n",
    "        frame_dict[frame] = len(frame_dict.keys())\n",
    "        frame_dict_rev[frame_dict[frame]] = frame\n",
    "    frame_id = frame_dict[frame]\n",
    "    \n",
    "    for sentence in lu[\"sentences\"]:\n",
    "        text = sentence[\"text\"]\n",
    "        indexes = sentence[\"indexes\"]        \n",
    "        start = min([int(i[0]) for i in indexes])\n",
    "        end = max([int(i[1]) for i in indexes])\n",
    "        inputs.append((text, start, end))\n",
    "        labels.append(frame_id)\n",
    "        \n",
    "print(\"# datapoints = \", len(labels))\n",
    "print(\"max labels = \", max(labels))\n",
    "print(len(frame_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset in =  tensor([-0.2417, -0.4016,  0.5359,  ...,  0.0000,  0.0000,  0.0000])\n",
      "dataset out =  tensor(4) torch.LongTensor\n",
      "dimensions: in = 3072  out =  829\n"
     ]
    }
   ],
   "source": [
    "# You should build your custom dataset as below.\n",
    "class FnBertDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, inputs, labels, frame_dict, tokenizer, bert_model):\n",
    "        \"\"\"\n",
    "        First two arguments should be lists with the format:\n",
    "        inputs: [(text1, start1, end1), ...]\n",
    "        labels: [label_id1, ...]\n",
    "        \"\"\"\n",
    "        self.inputs = inputs\n",
    "        self.labels = labels\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        self.bert_model = bert_model\n",
    "        \n",
    "        self.MAX_LEN = 4\n",
    "        self.INPUT_DIM = self.MAX_LEN * self.bert_model.config.hidden_size\n",
    "        self.OUTPUT_DIM = len(frame_dict.keys())\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        text, start, end = self.inputs[index]\n",
    "        x = self.get_bert_hidden_state(text, start, end)\n",
    "        y = torch.tensor(self.labels[index]).long()        \n",
    "        return x, y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def get_bert_hidden_state(self, text, start, end):\n",
    "        text = \"[CLS] \" + text + \" [SEP]\"\n",
    "        start += len(\"[CLS] \")\n",
    "        end += len(\"[CLS] \")\n",
    "        \n",
    "        # Compute start end end using token indexes\n",
    "        tk_start, tk_end = self.pos_to_token_idx(text, start, end)\n",
    "        tk_end = min(tk_start + self.MAX_LEN, tk_end)\n",
    "        # Tokenize input\n",
    "        tokenized_text = self.tokenizer.tokenize(text)\n",
    "    \n",
    "        # Convert token to vocabulary indices\n",
    "        indexed_tokens = self.tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "        # Convert inputs to PyTorch tensors\n",
    "        tokens_tensor = torch.tensor([indexed_tokens]).to('cuda')\n",
    "        # Predict hidden states features for each layer\n",
    "        with torch.no_grad():\n",
    "            outputs = self.bert_model(tokens_tensor)\n",
    "            # Hidden state of the last layer of the Bert model\n",
    "            hidden = torch.squeeze(outputs[0], dim = 0)\n",
    "            # Slice hidden state to hidden[start:end]\n",
    "            hidden = hidden.narrow(0, tk_start, tk_end-tk_start)\n",
    "            # Add padding\n",
    "            pad = torch.zeros(self.MAX_LEN, hidden.size()[1])            \n",
    "            pad[0:hidden.size()[0],:] = hidden\n",
    "            hidden = torch.flatten(pad)\n",
    "            return hidden\n",
    "\n",
    "    def pos_to_token_idx(self, text, start, end):\n",
    "        target_prefix = self.tokenizer.tokenize(text[:start])\n",
    "        target = self.tokenizer.tokenize(text[start:end+1])\n",
    "        tk_start = len(target_prefix)\n",
    "        tk_end = tk_start + len(target)\n",
    "        return tk_start, tk_end\n",
    "    \n",
    "dataset = FnBertDataset(inputs, labels, frame_dict, tokenizer, bert_model)\n",
    "print(\"dataset in = \", dataset[100][0])\n",
    "print(\"dataset out = \", dataset[100][1], dataset[100][1].type())\n",
    "print(\"dimensions: in =\", dataset.INPUT_DIM, \" out = \", dataset.OUTPUT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1,    20] loss: 5.960\n",
      "[ 1,    40] loss: 4.943\n",
      "[ 1,    60] loss: 4.548\n",
      "[ 1,    80] loss: 4.096\n",
      "[ 1,   100] loss: 3.701\n",
      "[ 1,   120] loss: 3.250\n",
      "[ 1,   140] loss: 2.935\n",
      "[ 1,   160] loss: 2.655\n",
      "[ 1,   180] loss: 2.268\n",
      "[ 1,   200] loss: 2.133\n",
      "[ 1,   220] loss: 1.843\n",
      "[ 1,   240] loss: 1.662\n",
      "[ 1,   260] loss: 1.471\n",
      "[ 1,   280] loss: 1.386\n",
      "[ 1,   300] loss: 1.276\n",
      "[ 1,   320] loss: 1.134\n",
      "[ 1,   340] loss: 1.065\n",
      "[ 1,   360] loss: 1.022\n",
      "[ 1,   380] loss: 1.028\n",
      "[ 1,   400] loss: 0.909\n",
      "[ 1,   420] loss: 0.987\n",
      "[ 1,   440] loss: 0.816\n",
      "[ 1,   460] loss: 0.798\n",
      "[ 1,   480] loss: 0.765\n",
      "[ 1,   500] loss: 0.706\n",
      "[ 1,   520] loss: 0.756\n",
      "[ 1,   540] loss: 0.664\n",
      "[ 1,   560] loss: 0.635\n",
      "[ 1,   580] loss: 0.643\n",
      "[ 1,   600] loss: 0.582\n",
      "[ 1,   620] loss: 0.615\n",
      "[ 2,    20] loss: 0.475\n",
      "[ 2,    40] loss: 0.411\n",
      "[ 2,    60] loss: 0.427\n",
      "[ 2,    80] loss: 0.379\n",
      "[ 2,   100] loss: 0.364\n",
      "[ 2,   120] loss: 0.365\n",
      "[ 2,   140] loss: 0.405\n",
      "[ 2,   160] loss: 0.427\n",
      "[ 2,   180] loss: 0.359\n",
      "[ 2,   200] loss: 0.360\n",
      "[ 2,   220] loss: 0.354\n",
      "[ 2,   240] loss: 0.377\n",
      "[ 2,   260] loss: 0.363\n",
      "[ 2,   280] loss: 0.346\n",
      "[ 2,   300] loss: 0.335\n",
      "[ 2,   320] loss: 0.374\n",
      "[ 2,   340] loss: 0.331\n",
      "[ 2,   360] loss: 0.378\n",
      "[ 2,   380] loss: 0.373\n",
      "[ 2,   400] loss: 0.348\n",
      "[ 2,   420] loss: 0.358\n",
      "[ 2,   440] loss: 0.382\n",
      "[ 2,   460] loss: 0.336\n",
      "[ 2,   480] loss: 0.344\n",
      "[ 2,   500] loss: 0.321\n",
      "[ 2,   520] loss: 0.325\n",
      "[ 2,   540] loss: 0.325\n",
      "[ 2,   560] loss: 0.340\n",
      "[ 2,   580] loss: 0.327\n",
      "[ 2,   600] loss: 0.318\n",
      "[ 2,   620] loss: 0.317\n",
      "[ 3,    20] loss: 0.197\n",
      "[ 3,    40] loss: 0.211\n",
      "[ 3,    60] loss: 0.200\n",
      "[ 3,    80] loss: 0.190\n",
      "[ 3,   100] loss: 0.216\n",
      "[ 3,   120] loss: 0.202\n",
      "[ 3,   140] loss: 0.192\n",
      "[ 3,   160] loss: 0.209\n",
      "[ 3,   180] loss: 0.212\n",
      "[ 3,   200] loss: 0.179\n",
      "[ 3,   220] loss: 0.204\n",
      "[ 3,   240] loss: 0.198\n",
      "[ 3,   260] loss: 0.200\n",
      "[ 3,   280] loss: 0.219\n",
      "[ 3,   300] loss: 0.207\n",
      "[ 3,   320] loss: 0.161\n",
      "[ 3,   340] loss: 0.247\n",
      "[ 3,   360] loss: 0.190\n",
      "[ 3,   380] loss: 0.194\n",
      "[ 3,   400] loss: 0.215\n",
      "[ 3,   420] loss: 0.207\n",
      "[ 3,   440] loss: 0.227\n",
      "[ 3,   460] loss: 0.190\n",
      "[ 3,   480] loss: 0.218\n",
      "[ 3,   500] loss: 0.202\n",
      "[ 3,   520] loss: 0.208\n",
      "[ 3,   540] loss: 0.189\n",
      "[ 3,   560] loss: 0.228\n",
      "[ 3,   580] loss: 0.224\n",
      "[ 3,   600] loss: 0.188\n",
      "[ 3,   620] loss: 0.194\n",
      "[ 4,    20] loss: 0.125\n",
      "[ 4,    40] loss: 0.115\n",
      "[ 4,    60] loss: 0.135\n",
      "[ 4,    80] loss: 0.130\n",
      "[ 4,   100] loss: 0.129\n",
      "[ 4,   120] loss: 0.126\n",
      "[ 4,   140] loss: 0.130\n",
      "[ 4,   160] loss: 0.128\n",
      "[ 4,   180] loss: 0.121\n",
      "[ 4,   200] loss: 0.125\n",
      "[ 4,   220] loss: 0.136\n",
      "[ 4,   240] loss: 0.130\n",
      "[ 4,   260] loss: 0.145\n",
      "[ 4,   280] loss: 0.129\n",
      "[ 4,   300] loss: 0.135\n",
      "[ 4,   320] loss: 0.142\n",
      "[ 4,   340] loss: 0.149\n",
      "[ 4,   360] loss: 0.141\n",
      "[ 4,   380] loss: 0.121\n",
      "[ 4,   400] loss: 0.141\n",
      "[ 4,   420] loss: 0.145\n",
      "[ 4,   440] loss: 0.151\n",
      "[ 4,   460] loss: 0.138\n",
      "[ 4,   480] loss: 0.143\n",
      "[ 4,   500] loss: 0.132\n",
      "[ 4,   520] loss: 0.136\n",
      "[ 4,   540] loss: 0.143\n",
      "[ 4,   560] loss: 0.138\n",
      "[ 4,   580] loss: 0.129\n",
      "[ 4,   600] loss: 0.141\n",
      "[ 4,   620] loss: 0.108\n",
      "[ 5,    20] loss: 0.089\n",
      "[ 5,    40] loss: 0.085\n",
      "[ 5,    60] loss: 0.094\n",
      "[ 5,    80] loss: 0.084\n",
      "[ 5,   100] loss: 0.074\n",
      "[ 5,   120] loss: 0.095\n",
      "[ 5,   140] loss: 0.088\n",
      "[ 5,   160] loss: 0.086\n",
      "[ 5,   180] loss: 0.106\n",
      "[ 5,   200] loss: 0.083\n",
      "[ 5,   220] loss: 0.088\n",
      "[ 5,   240] loss: 0.111\n",
      "[ 5,   260] loss: 0.091\n",
      "[ 5,   280] loss: 0.095\n",
      "[ 5,   300] loss: 0.088\n",
      "[ 5,   320] loss: 0.085\n",
      "[ 5,   340] loss: 0.087\n",
      "[ 5,   360] loss: 0.099\n",
      "[ 5,   380] loss: 0.083\n",
      "[ 5,   400] loss: 0.096\n",
      "[ 5,   420] loss: 0.114\n",
      "[ 5,   440] loss: 0.107\n",
      "[ 5,   460] loss: 0.105\n",
      "[ 5,   480] loss: 0.108\n",
      "[ 5,   500] loss: 0.119\n",
      "[ 5,   520] loss: 0.109\n",
      "[ 5,   540] loss: 0.103\n",
      "[ 5,   560] loss: 0.118\n",
      "[ 5,   580] loss: 0.125\n",
      "[ 5,   600] loss: 0.141\n",
      "[ 5,   620] loss: 0.144\n",
      "[ 6,    20] loss: 0.077\n",
      "[ 6,    40] loss: 0.078\n",
      "[ 6,    60] loss: 0.071\n",
      "[ 6,    80] loss: 0.067\n",
      "[ 6,   100] loss: 0.060\n",
      "[ 6,   120] loss: 0.059\n",
      "[ 6,   140] loss: 0.058\n",
      "[ 6,   160] loss: 0.060\n",
      "[ 6,   180] loss: 0.069\n",
      "[ 6,   200] loss: 0.071\n",
      "[ 6,   220] loss: 0.070\n",
      "[ 6,   240] loss: 0.077\n",
      "[ 6,   260] loss: 0.067\n",
      "[ 6,   280] loss: 0.071\n",
      "[ 6,   300] loss: 0.067\n",
      "[ 6,   320] loss: 0.074\n",
      "[ 6,   340] loss: 0.071\n",
      "[ 6,   360] loss: 0.071\n",
      "[ 6,   380] loss: 0.079\n",
      "[ 6,   400] loss: 0.072\n",
      "[ 6,   420] loss: 0.082\n",
      "[ 6,   440] loss: 0.074\n",
      "[ 6,   460] loss: 0.081\n",
      "[ 6,   480] loss: 0.104\n",
      "[ 6,   500] loss: 0.085\n",
      "[ 6,   520] loss: 0.092\n",
      "[ 6,   540] loss: 0.079\n",
      "[ 6,   560] loss: 0.084\n",
      "[ 6,   580] loss: 0.073\n",
      "[ 6,   600] loss: 0.100\n",
      "[ 6,   620] loss: 0.101\n",
      "[ 7,    20] loss: 0.066\n",
      "[ 7,    40] loss: 0.058\n",
      "[ 7,    60] loss: 0.055\n",
      "[ 7,    80] loss: 0.041\n",
      "[ 7,   100] loss: 0.050\n",
      "[ 7,   120] loss: 0.049\n",
      "[ 7,   140] loss: 0.052\n",
      "[ 7,   160] loss: 0.053\n",
      "[ 7,   180] loss: 0.050\n",
      "[ 7,   200] loss: 0.042\n",
      "[ 7,   220] loss: 0.051\n",
      "[ 7,   240] loss: 0.047\n",
      "[ 7,   260] loss: 0.056\n",
      "[ 7,   280] loss: 0.060\n",
      "[ 7,   300] loss: 0.046\n",
      "[ 7,   320] loss: 0.066\n",
      "[ 7,   340] loss: 0.061\n",
      "[ 7,   360] loss: 0.059\n",
      "[ 7,   380] loss: 0.061\n",
      "[ 7,   400] loss: 0.069\n",
      "[ 7,   420] loss: 0.052\n",
      "[ 7,   440] loss: 0.059\n",
      "[ 7,   460] loss: 0.067\n",
      "[ 7,   480] loss: 0.057\n",
      "[ 7,   500] loss: 0.060\n",
      "[ 7,   520] loss: 0.063\n",
      "[ 7,   540] loss: 0.077\n",
      "[ 7,   560] loss: 0.082\n",
      "[ 7,   580] loss: 0.099\n",
      "[ 7,   600] loss: 0.076\n",
      "[ 7,   620] loss: 0.088\n",
      "[ 8,    20] loss: 0.059\n",
      "[ 8,    40] loss: 0.041\n",
      "[ 8,    60] loss: 0.043\n",
      "[ 8,    80] loss: 0.038\n",
      "[ 8,   100] loss: 0.047\n",
      "[ 8,   120] loss: 0.041\n",
      "[ 8,   140] loss: 0.037\n",
      "[ 8,   160] loss: 0.051\n",
      "[ 8,   180] loss: 0.052\n",
      "[ 8,   200] loss: 0.038\n",
      "[ 8,   220] loss: 0.049\n",
      "[ 8,   240] loss: 0.035\n",
      "[ 8,   260] loss: 0.053\n",
      "[ 8,   280] loss: 0.052\n",
      "[ 8,   300] loss: 0.051\n",
      "[ 8,   320] loss: 0.057\n",
      "[ 8,   340] loss: 0.043\n",
      "[ 8,   360] loss: 0.061\n",
      "[ 8,   380] loss: 0.054\n",
      "[ 8,   400] loss: 0.050\n",
      "[ 8,   420] loss: 0.054\n",
      "[ 8,   440] loss: 0.048\n",
      "[ 8,   460] loss: 0.059\n",
      "[ 8,   480] loss: 0.057\n",
      "[ 8,   500] loss: 0.043\n",
      "[ 8,   520] loss: 0.060\n",
      "[ 8,   540] loss: 0.066\n",
      "[ 8,   560] loss: 0.060\n",
      "[ 8,   580] loss: 0.061\n",
      "[ 8,   600] loss: 0.048\n",
      "[ 8,   620] loss: 0.050\n",
      "[ 9,    20] loss: 0.044\n",
      "[ 9,    40] loss: 0.032\n",
      "[ 9,    60] loss: 0.034\n",
      "[ 9,    80] loss: 0.031\n",
      "[ 9,   100] loss: 0.037\n",
      "[ 9,   120] loss: 0.032\n",
      "[ 9,   140] loss: 0.038\n",
      "[ 9,   160] loss: 0.031\n",
      "[ 9,   180] loss: 0.045\n",
      "[ 9,   200] loss: 0.034\n",
      "[ 9,   220] loss: 0.049\n",
      "[ 9,   240] loss: 0.045\n",
      "[ 9,   260] loss: 0.047\n",
      "[ 9,   280] loss: 0.041\n",
      "[ 9,   300] loss: 0.039\n",
      "[ 9,   320] loss: 0.039\n",
      "[ 9,   340] loss: 0.033\n",
      "[ 9,   360] loss: 0.031\n",
      "[ 9,   380] loss: 0.036\n",
      "[ 9,   400] loss: 0.043\n",
      "[ 9,   420] loss: 0.051\n",
      "[ 9,   440] loss: 0.044\n",
      "[ 9,   460] loss: 0.048\n",
      "[ 9,   480] loss: 0.047\n",
      "[ 9,   500] loss: 0.045\n",
      "[ 9,   520] loss: 0.044\n",
      "[ 9,   540] loss: 0.038\n",
      "[ 9,   560] loss: 0.045\n",
      "[ 9,   580] loss: 0.046\n",
      "[ 9,   600] loss: 0.046\n",
      "[ 9,   620] loss: 0.050\n",
      "[10,    20] loss: 0.043\n",
      "[10,    40] loss: 0.023\n",
      "[10,    60] loss: 0.032\n",
      "[10,    80] loss: 0.026\n",
      "[10,   100] loss: 0.049\n",
      "[10,   120] loss: 0.031\n",
      "[10,   140] loss: 0.026\n",
      "[10,   160] loss: 0.024\n",
      "[10,   180] loss: 0.037\n",
      "[10,   200] loss: 0.023\n",
      "[10,   220] loss: 0.025\n",
      "[10,   240] loss: 0.025\n",
      "[10,   260] loss: 0.031\n",
      "[10,   280] loss: 0.026\n",
      "[10,   300] loss: 0.032\n",
      "[10,   320] loss: 0.026\n",
      "[10,   340] loss: 0.035\n",
      "[10,   360] loss: 0.029\n",
      "[10,   380] loss: 0.026\n",
      "[10,   400] loss: 0.029\n",
      "[10,   420] loss: 0.023\n",
      "[10,   440] loss: 0.042\n",
      "[10,   460] loss: 0.040\n",
      "[10,   480] loss: 0.041\n",
      "[10,   500] loss: 0.051\n",
      "[10,   520] loss: 0.038\n",
      "[10,   540] loss: 0.036\n",
      "[10,   560] loss: 0.054\n",
      "[10,   580] loss: 0.044\n",
      "[10,   600] loss: 0.055\n",
      "[10,   620] loss: 0.039\n",
      "Training finished\n"
     ]
    }
   ],
   "source": [
    "def create_net(input_dim, output_dim):\n",
    "    layers = [\n",
    "        nn.Linear(input_dim, 200),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(200, output_dim),\n",
    "    ]\n",
    "    model = nn.Sequential(*layers)\n",
    "    return model\n",
    "\n",
    "# Run training & testing\n",
    "net = create_net(input_dim = dataset.INPUT_DIM, output_dim = dataset.OUTPUT_DIM)\n",
    "model = Model(net, criterion = nn.CrossEntropyLoss(),\n",
    "              optimizer=optim.Adam(net.parameters(), lr=10e-4))\n",
    "model.fit(dataset, n_epochs=10, batch_size=32, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'C:\\\\Users\\\\danil\\\\Documents\\\\Northwestern\\\\Research\\\\projects\\\\frame_classification\\\\state_dict')\n",
    "torch.save(net, 'C:\\\\Users\\\\danil\\\\Documents\\\\Northwestern\\\\Research\\\\projects\\\\frame_classification\\\\net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "Accuracy on the 500 data points: 97 %\n"
     ]
    }
   ],
   "source": [
    "dev_dataset = FnBertDataset(inputs[500:1000], labels[500:1000], frame_dict, tokenizer, bert_model)\n",
    "print(len(dev_dataset))\n",
    "model.test(dev_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Duplication', 'Body_movement', 'Topic', 'Reliance', 'Revenge', 'Reliance_on_expectation', 'Recovery', 'Emptying', 'Law', 'Being_located', 'Practice', 'Speed_description', 'Taking_time', 'Shaped_part', 'Architectural_part', 'Filling', 'Age', 'People_by_age', 'People_by_origin', 'Losing_it', 'Grasp', 'Craft', 'Building_subparts', 'Change_event_time', 'Attempt_suasion', 'Perception_body', 'Cause_change_of_position_on_a_scale', 'Conduct', 'Type', 'Body_mark', 'Perception_experience', 'Departing', 'Desirability', 'Gizmo', 'Contingency', 'Idiosyncrasy', 'Moving_in_place', 'Cause_to_make_noise', 'Education_teaching', 'Communication', 'Excreting', 'Capability', 'Motion_noise', 'Rest', 'Increment', 'Political_locales', 'Emotion_active', 'Change_of_leadership', 'Text', 'Natural_features', 'Attempt', 'Perception_active', 'Sensation', 'Partitive', 'Evoking', 'Locale_by_use', 'Aesthetics', 'Noise_makers', 'Request', 'Rite', 'Religious_belief', 'People_by_religion', 'Social_event', 'Buildings', 'People_by_jurisdiction', 'Stimulus_focus', 'Experiencer_focus', 'Halt', 'Connecting_architecture', 'Body_parts', 'Membership', 'Cardinal_numbers', 'First_experience', 'Desiring', 'Identicality', 'Feeling', 'Wealthiness', 'Part_whole', 'Remainder', 'Existence', 'Temporal_pattern', 'Left_to_do', 'Temperature', 'Artifact', 'Posture', 'Medical_conditions', 'Omen', 'Ambient_temperature', 'Heralding', 'Cause_to_continue', 'Frugality', 'Locale', 'Morality_evaluation', 'Cause_harm', 'Transition_to_state', 'People_by_vocation', 'Encoding', 'Spelling_and_pronouncing', 'Relative_time', 'Prevarication', 'Subjective_influence', 'Objective_influence', 'Make_acquaintance', 'Clemency', 'Commutation', 'Hostile_encounter', 'Subversion', 'Performers', 'Legality', 'Body_description_holistic', 'Compliance', 'Misdeed', 'People_by_morality', 'Guilt_or_innocence', 'Imprisonment', 'Sentencing', 'Get_a_job', 'Being_employed', 'Hiring', 'Path_shape', 'Beyond_compare', 'Judgment_communication', 'Judgment_direct_address', 'Time_vector', 'Replacing', 'Fining', 'Origin', 'Studying', 'Memorization', 'Similarity', 'Distinctiveness', 'Typicality', 'Intentionally_act', 'Cotheme', 'Using', 'Leadership', 'Participation', 'Weapon', 'Secrecy_status', 'Processing_materials', 'Discussion', 'Commitment', 'Emotion_directed', 'Reveal_secret', 'Attributed_information', 'Cause_to_end', 'Sign_agreement', 'Research', 'Inclusion', 'Unattributed_information', 'Sending', 'State_continue', 'Aggregate', 'Activity_resume', 'Intentionally_create', 'Being_necessary', 'Collaboration', 'Purpose', 'Degree_of_processing', 'Project', 'Toxic_substance', 'Being_obligatory', 'Exchange', 'Take_place_of', 'Judgment', 'Goal', 'Interior_profile_relation', 'Undergo_change', 'Cause_change', 'Receiving', 'Transfer', 'Exchange_currency', 'Categorization', 'Change_tool', 'Placing', 'Volubility', 'Evidence', 'Causation', 'Being_operational', 'Likelihood', 'Render_nonfunctional', 'Awareness', 'Process_end', 'Cogitation', 'Locative_relation', 'Gesture', 'Hindering', 'Manipulation', 'Cause_motion', 'Sounds', 'Motion', 'Wearing', 'Scrutiny', 'Undressing', 'Dressing', 'Impact', 'Statement', 'Remembering_experience', 'Remembering_information', 'Remembering_to_do', 'Cognitive_connection', 'Verification', 'Renunciation', 'Sleep', 'Arriving', 'Possession', 'Amounting_to', 'Behind_the_scenes', 'Being_dry', 'Being_in_operation', 'Body_description_part', 'Businesses', 'Cause_change_of_phase', 'Cause_fluidic_motion', 'Cause_impact', 'Cause_to_be_dry', 'Cause_to_move_in_place', 'Chatting', 'Claim_ownership', 'Commerce_scenario', 'Communication_means', 'Compatibility', 'Clothing', 'Contacting', 'Containers', 'Damaging', 'Deserving', 'Direction', 'Documents', 'Employing', 'Evaluative_comparison', 'Exclude_member', 'Execution', 'Expansion', 'Removing', 'Experience_bodily_harm', 'Finish_competition', 'Hair_configuration', 'Change_of_temperature', 'Labeling', 'Sufficiency', 'Namesake', 'Referring_by_name', 'Locating', 'Simple_name', 'Simple_naming', 'Make_noise', 'Measure_by_action', 'Ordinal_numbers', 'Partiality', 'Part_inner_outer', 'Part_ordered_segments', 'People_by_residence', 'Grooming', 'Inspecting', 'Scouring', 'Preventing_or_letting', 'Preserving', 'Personal_relationship', 'Piracy', 'Offenses', 'Activity_stop', 'Cause_change_of_consistency', 'Cause_expansion', 'Creating', 'Boundary', 'Sharpness', 'Becoming_silent', 'Activity_finish', 'Activity_ongoing', 'Activity_pause', 'Activity_prepare', 'Cause_to_be_sharp', 'Becoming_attached', 'Shapes', 'Committing_crime', 'Manufacturing', 'Event', 'Commercial_transaction', 'Being_named', 'Operational_testing', 'Response', 'Forgoing', 'Dodging', 'Elusive_goal', 'Taking_sides', 'Traversing', 'Self_motion', 'Robbery', 'Assistance', 'Destroying', 'Substance', 'Active_substance', 'Defending', 'Usefulness', 'Expertise', 'Progression', 'Stage_of_progress', 'Change_position_on_a_scale', 'Make_agreement_on_action', 'Delivery', 'Fields', 'Supply', 'Source_of_getting', 'Ingredients', 'Process_continue', 'Endangering', 'Dispersal', 'First_rank', 'Coming_up_with', 'Shoot_projectiles', 'Quantified_mass', 'Cause_to_make_progress', 'People', 'Arranging', 'Candidness', 'Kinship', 'Range', 'Attaching', 'Ratification', 'Obviousness', 'Come_together', 'Extradition', 'Organization', 'Cause_to_resume', 'Needing', 'Adjusting', 'Rank', 'Difficulty', 'Reassuring', 'Occupy_rank', 'Be_in_agreement_on_action', 'Required_event', 'Desirable_event', 'Getting_vehicle_underway', 'Success_or_failure', 'Successful_action', 'Detaching', 'Absorb_heat', 'Distributed_position', 'Amalgamation', 'Apply_heat', 'Arrest', 'Assessing', 'Attack', 'Regard', 'Avoiding', 'Being_detached', 'Becoming_aware', 'Giving_birth', 'Opinion', 'Breathing', 'Experiencer_obj', 'Mental_property', 'Quitting', 'Getting_up', 'Dough_rising', 'Resurrection', 'Building', 'Bungling', 'Sidereal_appearance', 'Bringing', 'Being_up_to_it', 'Rising_to_a_challenge', 'Inhibit_movement', 'Giving', 'Cause_temperature_change', 'Cause_to_amalgamate', 'Cause_to_be_wet', 'Cause_to_experience', 'Cause_to_fragment', 'Waking_up', 'Cause_to_start', 'Certainty', 'Prominence', 'Change_of_consistency', 'Within_distance', 'Explaining_the_facts', 'Temporal_subregion', 'Seeking_to_achieve', 'Getting', 'Infrastructure', 'Amassing', 'Foreign_or_domestic_country', 'Relational_natural_features', 'Have_as_requirement', 'Imposing_obligation', 'Accoutrements', 'Operating_a_system', 'Giving_in', 'Surrendering_possession', 'Importance', 'Be_in_agreement_on_assessment', 'Being_in_effect', 'Store', 'Correctness', 'Military', 'Estimating', 'Estimated_value', 'Activity_ready_state', 'Withdraw_from_participation', 'Submitting_documents', 'Accomplishment', 'Intercepting', 'Coming_to_believe', 'Resolve_problem', 'Redirecting', 'Terms_of_agreement', 'Used_up', 'Ranked_expectation', 'Electricity', 'Completeness', 'Being_active', 'Installing', 'Measure_mass', 'Emphasizing', 'Convey_importance', 'Gathering_up', 'Storing', 'Indigenous_origin', 'Being_at_risk', 'Waiting', 'Margin_of_resolution', 'People_along_political_spectrum', 'Ammunition', 'Importing', 'Going_back_on_a_commitment', 'Exporting', 'Level_of_force_exertion', 'Reforming_a_system', 'Suitability', 'Economy', 'Extreme_point', 'Alliance', 'Competition', 'Holding_off_on', 'Waver_between_options', 'Actually_occurring_entity', 'Rashness', 'Proper_reference', 'Adopt_selection', 'Information', 'Path_traveled', 'Frequency', 'Continued_state_of_affairs', 'Extreme_value', 'Familiarity', 'Fastener', 'Bearing_arms', 'Proliferating_in_number', 'State_of_entity', 'Adducing', 'Abundance', 'Scarcity', 'Institutions', 'Public_services', 'Unemployment_rate', 'Judicial_body', 'Point_of_dispute', 'Sent_items', 'System', 'Network', 'Disgraceful_situation', 'Recording', 'Rejuvenation', 'Set_of_interrelated_entities', 'Operate_vehicle', 'Expected_location_of_person', 'Reason', 'Reporting', 'Being_attached', 'Ingestion', 'Institutionalization', 'Complaining', 'Expressing_publicly', 'Respond_to_proposal', 'Bragging', 'Agree_or_refuse_to_act', 'Preference', 'Dead_or_alive', 'Choosing', 'Protecting', 'Willingness', 'Board_vehicle', 'Disembarking', 'Cutting', 'Change_posture', 'Activity_start', 'Motion_directional', 'Surpassing', 'Getting_underway', 'Intentional_traversing', 'Quitting_a_place', 'Translating', 'Setting_out', 'Successfully_communicate_message', 'Change_direction', 'Intoxication', 'Have_as_translation_equivalent', 'Physical_artworks', 'Create_representation', 'Be_translation_equivalent', 'Create_physical_artwork', 'Fleeing', 'Artificiality', 'Forging', 'Feigning', 'Posing_as', 'Passing_off', 'Imitating', 'Hiding_objects', 'Delimitation_of_diversity', 'Being_awake', 'Change_operational_state', 'Becoming_detached', 'Expectation', 'Manipulate_into_doing', 'Summarizing', 'Food', 'Vehicle', 'Releasing', 'Undergoing', 'Execute_plan', 'Entity', 'Renting', 'Renting_out', 'Becoming_a_member', 'Trust', 'Containing', 'Front_for', 'Give_impression', 'Make_cognitive_connection', 'Social_connection', 'Communication_response', 'Predicting', 'Text_creation', 'Medical_professionals', 'Terrorism', 'Catastrophe', 'Money', 'Risky_situation', 'Run_risk', 'Eventive_cognizer_affecting', 'Fairness_evaluation', 'Abusing', 'Differentiation', 'Change_event_duration', 'Commerce_pay', 'Weather', 'Ride_vehicle', 'Reasoning', 'Measure_duration', 'Measure_linear_extent', 'Custom', 'Ground_up', 'Reading_perception', 'Addiction', 'Abounding_with', 'Thriving', 'Cause_change_of_strength', 'Change_resistance', 'Subordinates_and_superiors', 'Means', 'Surviving', 'Colonization', 'Communicate_categorization', 'Dominate_situation', 'Dominate_competitor', 'Control', 'Being_in_control', 'Destiny', 'Luck', 'Coincidence', 'Enforcing', 'Separating', 'Besieging', 'Be_subset_of', 'Being_in_category', 'Connectors', 'Vocalizations', 'Carry_goods', 'Breaking_off', 'Breaking_apart', 'Becoming_separated', 'Having_or_lacking_access', 'Openness', 'Calendric_unit', 'Earnings_and_losses', 'Social_interaction_evaluation', 'Performing_arts', 'Fame', 'Obscurity', 'Duration_description', 'Shopping', 'Performers_and_roles', 'Relational_political_locales', 'Trendiness', 'Temporary_stay', 'Travel', 'Coming_to_be', 'Quarreling', 'Work', 'Position_on_a_scale', 'Diversity', 'Interrupt_process', 'Temporal_collocation', 'Simultaneity', 'Aiming', 'Hit_or_miss', 'Accuracy', 'Lively_place', 'Cause_proliferation_in_number', 'Individual_history', 'Historic_event', 'Touring', 'Visiting', 'Provide_lodging', 'Residence', 'Location_of_light', 'Aging', 'Locale_by_event', 'Presence', 'Proportional_quantity', 'Reference_text', 'Appointing', 'Nuclear_process', 'Intentionally_affect', 'Scope', 'Preliminaries', 'Part_orientational', 'Attention', 'Ineffability', 'Alternatives', 'Have_associated', 'Guest_and_host', 'Have_visitor_over', 'Drop_in_on', 'Version_sequence', 'Hospitality', 'Roadways', 'Biological_area', 'Process_stop', 'Deny_or_grant_permission', 'Commemorative', 'Killing', 'Name_conferral', 'Commerce_sell', 'Sign', 'Prohibiting_or_licensing', 'Supporting', 'Degree', 'Medium', 'Surrendering', 'Hunting', 'Food_gathering', 'Hunting_success_or_failure', 'Agriculture', 'Growing_food', 'Planting', 'Conquering', 'Invading', 'Repel', 'Becoming_dry', 'Attending', 'Abandonment', 'Soaking_up', 'Cause_emotion', 'Cure', 'Emotions_by_stimulus', 'Emotions_success_or_failure', 'Mental_stimulus_exp_focus', 'Emotions_of_mental_activity', 'Mental_stimulus_stimulus_focus', 'Others_situation_as_stimulus', 'Annoyance', 'Just_found_out', 'Fear', 'Death', 'Dying', 'Prevent_or_allow_possession', 'Confronting_problem', 'Relating_concepts', 'Level_of_force_resistance', 'Precipitation', 'Taking', 'Corporal_punishment', 'Reshaping', 'Launch_process', 'Eventive_affecting', 'Theft', 'Win_prize', 'Beat_opponent', 'Punctual_perception', 'Legal_rulings', 'Mention', 'Indicating', 'Out_of_existence', 'Ceasing_to_be', 'History', 'Possibility', 'Duration_relation', 'Ingest_substance', 'Tolerating', 'Attempt_means', 'Thwarting', 'Pattern', 'Sequence', 'Manipulate_into_shape', 'Capacity', 'Speak_on_topic', 'Event_instance', 'Location_in_time', 'Concessive', 'Cause_to_perceive', 'Labor_product', 'Locale_by_ownership', 'Sound_level', 'Representing', 'Fall_asleep', 'Short_selling', 'Timespan', 'Measurable_attributes', 'Attention_getting', 'Dimension', 'Being_obligated', 'Turning_out', 'Passing', 'Dunking', 'Losing_someone', 'Losing', 'Finish_game', 'Losing_track_of_theme', 'Losing_track_of_perceiver', 'Change_of_quantity_of_possession', 'Immobilization', 'Go_into_shape', 'Reading_aloud', 'Expend_resource', 'Cause_to_be_included', 'Meet_with_response', 'Satisfying', 'Meet_specifications', 'Offering', 'Meet_with', 'Wagering', 'Assemble', 'Cause_to_rot', 'Commutative_process', 'Commutative_statement', 'Non-commutative_process', 'Non-commutative_statement', 'Encounter', 'Race_descriptor', 'Exemplar', 'Exemplariness', 'Impression', 'Color_qualities', 'Social_event_collective', 'Social_event_individuals', 'Size', 'Subjective_temperature', 'Heat_potential', 'Time_period_of_action', 'Optical_image', 'Cause_bodily_experience', 'Tasting', 'Trying_out', 'Opportunity', 'Probability', 'Repayment', 'Bond_maturation', 'Popularity', 'Appellations', 'Exercising', 'Personal_success', 'Rate_description', 'Rate_quantification', 'Vehicle_subpart', 'Price_per_unit', 'Proportion', 'Relational_quantity', 'Mining', 'System_complexity', 'Sociability', 'Authority', 'Artifact_subpart', 'Light_movement', 'Using_resource', 'Erasing', 'Political_actions', 'Artistic_style', 'Strictness', 'Cognitive_impact', 'Contrary_circumstances', 'Leaving_traces', 'Sports_jargon', 'Graph_shape', 'Serving_in_capacity', 'Function', 'Product_line', 'Being_relevant', 'Notability', 'Thermodynamic_phase', 'Substance_by_phase', 'Subsisting', 'Manner_of_life', 'Manner', 'Living_conditions', 'Planned_trajectory', 'Biological_entity', 'Gusto', 'Intentional_deception', 'Fall_for', 'Detonate_explosive', 'Cache', 'Explosion', 'Trap', 'Biological_urge', 'Triggering', 'Becoming_visible', 'Rebellion', 'Revolution', 'Prank', 'Protest', 'Temporary_group', 'Entourage', 'Awareness_status', 'Convoy', 'Irregular_combatants'])\n",
      "('She copied her costume from a film poster in the bar-tabac in the village . ', 4, 9) Duplication\n"
     ]
    }
   ],
   "source": [
    "print(frame_dict.keys())\n",
    "print(frame_dict.keys())\n",
    "print(inputs[0], frame_dict_rev[labels[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_top_k_dataset(dataset, k, batch_size=1):\n",
    "        predicted_lst = []\n",
    "        probs_lst = []\n",
    "        data_loader = torch.utils.data.DataLoader(\n",
    "            dataset=dataset, batch_size=batch_size, shuffle=False)    \n",
    "        with torch.no_grad():\n",
    "            for (inputs, _) in data_loader:\n",
    "                inputs = inputs.to(\"cuda\")\n",
    "                predicted, probs = predict_top_k(inputs, k)\n",
    "                predicted_lst.append(predicted)\n",
    "                probs_lst.append(probs)\n",
    "        predicted_tensor = torch.cat(predicted_lst, 0)\n",
    "        probs_tensor = torch.cat(probs_lst, 0)\n",
    "        return predicted_tensor, probs_tensor\n",
    "    \n",
    "def predict_top_k(inputs, k, batch_size=1):\n",
    "    inputs = inputs.to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        outputs = net(inputs)\n",
    "        logits, predicted = torch.topk(outputs.data, k, dim = 1)\n",
    "        softmax = nn.Softmax(dim=1)\n",
    "        probs = softmax(logits)\n",
    "        return predicted, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Duplication', 0.68), ('Correctness', 0.16), ('Spelling_and_pronouncing', 0.1), ('Forging', 0.04), ('Location_in_time', 0.02)]\n",
      "[('Causation', 0.59), ('Explaining_the_facts', 0.34), ('Location_in_time', 0.06), ('Destiny', 0.01), ('Purpose', 0.01)]\n",
      "[('Weapon', 0.26), ('Conduct', 0.21), ('People_by_age', 0.19), ('Misdeed', 0.18), ('Measure_linear_extent', 0.15)]\n",
      "[('Medical_conditions', 0.53), ('Posture', 0.14), ('Individual_history', 0.13), ('Locale_by_use', 0.13), ('Timespan', 0.07)]\n",
      "[('Opinion', 0.58), ('Probability', 0.23), ('Awareness', 0.08), ('Military', 0.06), ('Mental_property', 0.04)]\n"
     ]
    }
   ],
   "source": [
    "dev_in = [\n",
    "    (\"the problem is telling which is the original document and which the copy\", 68, 71),\n",
    "    (\"the cause of the accident is not clear\", 4, 8),\n",
    "    (\"Rubella, also known as German measles or three-day measles, is an infection caused by the rubella virus.\", 0, 6),\n",
    "    (\"he died after a long illness\", 21, 27),\n",
    "    (\"for a time revolution was a strong probability\", 35, 45),\n",
    "]\n",
    "dev_lab = [\n",
    "    frame_dict[\"Duplication\"], frame_dict[\"Causation\"], \n",
    "    frame_dict[\"Medical_conditions\"], frame_dict[\"Medical_conditions\"],\n",
    "    frame_dict[\"Probability\"]\n",
    "]\n",
    "dev_dataset = FnBertDataset(dev_in, dev_lab, frame_dict, tokenizer, bert_model)\n",
    "preds, probs = predict_top_k_dataset(dev_dataset, 5)\n",
    "preds = preds.tolist()\n",
    "probs = probs.tolist()\n",
    "for pred, prob in zip(preds, probs):\n",
    "    print([(frame_dict_rev[x], round(y, 2)) for x, y in zip(pred, prob)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
